{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dbec47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e07a8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e8de02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "167442b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test=train_test_split(X,Y,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "41947f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_s = [0.001,0.0001,0.00001,0.01]\n",
    "tol_s = [1e-4,1e-5,1e-2,1e-1]\n",
    "fit_intercept_s = [True,False]\n",
    "max_iter_s = [1000,500,1500,800,1200,2000]\n",
    "shuffle_s = [True,False]\n",
    "early_stopping_s = [True,False]\n",
    "verbose_s = [0,1,2,3,5,6]\n",
    "warm_start_s = [True,False]\n",
    "n_jobs_s = [1,2,3,4]\n",
    "validation_fraction_s = [0.1,0.2,0.3,0.05]\n",
    "n_iter_no_change_s = [5,3,6,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8528ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tol_s = random.choice(tol_s)\n",
    "alpha_s  = random.choice(alpha_s)\n",
    "fit_intercept_s = random.choice(fit_intercept_s)\n",
    "max_iter_s = random.choice(max_iter_s)\n",
    "shuffle_s = random.choice(shuffle_s)\n",
    "verbose_s = random.choice(verbose_s)\n",
    "warm_start_s = random.choice(warm_start_s)\n",
    "n_jobs_s = random.choice(n_jobs_s)\n",
    "early_stopping_s = random.choice(early_stopping_s)\n",
    "validation_fraction_s = random.choice(validation_fraction_s)\n",
    "n_iter_no_change_s = random.choice(n_iter_no_change_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "736f6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(tol=tol_s,alpha=alpha_s,fit_intercept=fit_intercept_s,max_iter=max_iter_s,shuffle=shuffle_s,verbose=verbose_s,warm_start=warm_start_s,n_jobs=n_jobs_s,early_stopping=early_stopping_s,validation_fraction=validation_fraction_s,n_iter_no_change=n_iter_no_change_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "96c14224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 12.83, NNZs: 2, Bias: 1.000000, T: 105, Avg. loss: 3.839048\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.51, NNZs: 2, Bias: 1.000000, T: 210, Avg. loss: 2.475238\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 22.56, NNZs: 2, Bias: 2.000000, T: 315, Avg. loss: 0.866952\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30.34, NNZs: 2, Bias: 3.000000, T: 420, Avg. loss: 1.564667\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 30.88, NNZs: 2, Bias: 3.000000, T: 525, Avg. loss: 0.532762\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 35.21, NNZs: 2, Bias: 4.000000, T: 630, Avg. loss: 1.026381\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.76, NNZs: 2, Bias: 4.000000, T: 735, Avg. loss: 0.504952\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 38.35, NNZs: 2, Bias: 5.000000, T: 840, Avg. loss: 0.750762\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 38.50, NNZs: 2, Bias: 5.000000, T: 945, Avg. loss: 0.229524\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 43.86, NNZs: 2, Bias: 5.000000, T: 1050, Avg. loss: 0.863714\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 44.73, NNZs: 2, Bias: 6.000000, T: 1155, Avg. loss: 0.393619\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 44.87, NNZs: 2, Bias: 6.000000, T: 1260, Avg. loss: 0.223810\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 45.02, NNZs: 2, Bias: 6.000000, T: 1365, Avg. loss: 0.220000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 48.14, NNZs: 2, Bias: 6.000000, T: 1470, Avg. loss: 0.796381\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 49.82, NNZs: 2, Bias: 7.000000, T: 1575, Avg. loss: 0.485619\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 49.97, NNZs: 2, Bias: 7.000000, T: 1680, Avg. loss: 0.215238\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 50.12, NNZs: 2, Bias: 7.000000, T: 1785, Avg. loss: 0.211429\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 53.18, NNZs: 2, Bias: 7.000000, T: 1890, Avg. loss: 0.730476\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 54.07, NNZs: 2, Bias: 8.000000, T: 1995, Avg. loss: 0.282667\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 54.22, NNZs: 2, Bias: 8.000000, T: 2100, Avg. loss: 0.210286\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 54.37, NNZs: 2, Bias: 8.000000, T: 2205, Avg. loss: 0.206476\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 54.92, NNZs: 2, Bias: 8.000000, T: 2310, Avg. loss: 0.402190\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 56.39, NNZs: 2, Bias: 9.000000, T: 2415, Avg. loss: 0.801333\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 56.54, NNZs: 2, Bias: 9.000000, T: 2520, Avg. loss: 0.205143\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 56.70, NNZs: 2, Bias: 9.000000, T: 2625, Avg. loss: 0.201333\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 57.26, NNZs: 2, Bias: 9.000000, T: 2730, Avg. loss: 0.385333\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 58.12, NNZs: 2, Bias: 10.000000, T: 2835, Avg. loss: 0.725619\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 58.26, NNZs: 2, Bias: 10.000000, T: 2940, Avg. loss: 0.207619\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 58.41, NNZs: 2, Bias: 10.000000, T: 3045, Avg. loss: 0.203810\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 58.56, NNZs: 2, Bias: 10.000000, T: 3150, Avg. loss: 0.200000\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 59.11, NNZs: 2, Bias: 10.000000, T: 3255, Avg. loss: 0.380571\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 60.58, NNZs: 2, Bias: 11.000000, T: 3360, Avg. loss: 0.724000\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 60.73, NNZs: 2, Bias: 11.000000, T: 3465, Avg. loss: 0.198667\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 60.88, NNZs: 2, Bias: 11.000000, T: 3570, Avg. loss: 0.194857\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 62.40, NNZs: 2, Bias: 11.000000, T: 3675, Avg. loss: 0.641048\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 62.68, NNZs: 2, Bias: 12.000000, T: 3780, Avg. loss: 0.210571\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 62.83, NNZs: 2, Bias: 12.000000, T: 3885, Avg. loss: 0.199238\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 62.98, NNZs: 2, Bias: 12.000000, T: 3990, Avg. loss: 0.195429\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 63.13, NNZs: 2, Bias: 12.000000, T: 4095, Avg. loss: 0.191619\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 64.64, NNZs: 2, Bias: 12.000000, T: 4200, Avg. loss: 0.612286\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 64.82, NNZs: 2, Bias: 13.000000, T: 4305, Avg. loss: 0.215238\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 64.97, NNZs: 2, Bias: 13.000000, T: 4410, Avg. loss: 0.191619\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 65.13, NNZs: 2, Bias: 13.000000, T: 4515, Avg. loss: 0.187810\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 66.64, NNZs: 2, Bias: 13.000000, T: 4620, Avg. loss: 0.580667\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 66.81, NNZs: 2, Bias: 14.000000, T: 4725, Avg. loss: 0.206857\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 66.96, NNZs: 2, Bias: 14.000000, T: 4830, Avg. loss: 0.187810\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 67.12, NNZs: 2, Bias: 14.000000, T: 4935, Avg. loss: 0.184000\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 68.05, NNZs: 2, Bias: 15.000000, T: 5040, Avg. loss: 0.551714\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 69.05, NNZs: 2, Bias: 15.000000, T: 5145, Avg. loss: 0.428762\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 69.20, NNZs: 2, Bias: 15.000000, T: 5250, Avg. loss: 0.188000\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 69.35, NNZs: 2, Bias: 15.000000, T: 5355, Avg. loss: 0.184190\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 69.94, NNZs: 2, Bias: 15.000000, T: 5460, Avg. loss: 0.354190\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 70.28, NNZs: 2, Bias: 16.000000, T: 5565, Avg. loss: 0.544190\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 70.43, NNZs: 2, Bias: 16.000000, T: 5670, Avg. loss: 0.188000\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 70.58, NNZs: 2, Bias: 16.000000, T: 5775, Avg. loss: 0.184190\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 70.73, NNZs: 2, Bias: 16.000000, T: 5880, Avg. loss: 0.180381\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 71.33, NNZs: 2, Bias: 16.000000, T: 5985, Avg. loss: 0.338952\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 71.66, NNZs: 2, Bias: 17.000000, T: 6090, Avg. loss: 0.542286\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 71.80, NNZs: 2, Bias: 17.000000, T: 6195, Avg. loss: 0.184190\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 71.96, NNZs: 2, Bias: 17.000000, T: 6300, Avg. loss: 0.180381\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 72.11, NNZs: 2, Bias: 17.000000, T: 6405, Avg. loss: 0.176571\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 73.17, NNZs: 2, Bias: 17.000000, T: 6510, Avg. loss: 0.412286\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 73.14, NNZs: 2, Bias: 18.000000, T: 6615, Avg. loss: 0.388571\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 73.29, NNZs: 2, Bias: 18.000000, T: 6720, Avg. loss: 0.179238\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 73.45, NNZs: 2, Bias: 18.000000, T: 6825, Avg. loss: 0.175429\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 74.05, NNZs: 2, Bias: 18.000000, T: 6930, Avg. loss: 0.320857\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 74.17, NNZs: 2, Bias: 19.000000, T: 7035, Avg. loss: 0.648762\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 74.32, NNZs: 2, Bias: 19.000000, T: 7140, Avg. loss: 0.178095\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 74.47, NNZs: 2, Bias: 19.000000, T: 7245, Avg. loss: 0.174286\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 75.07, NNZs: 2, Bias: 19.000000, T: 7350, Avg. loss: 0.317429\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 75.20, NNZs: 2, Bias: 20.000000, T: 7455, Avg. loss: 0.634857\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 75.35, NNZs: 2, Bias: 20.000000, T: 7560, Avg. loss: 0.176952\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 75.50, NNZs: 2, Bias: 20.000000, T: 7665, Avg. loss: 0.173143\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 75.69, NNZs: 2, Bias: 20.000000, T: 7770, Avg. loss: 0.204095\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 76.30, NNZs: 2, Bias: 21.000000, T: 7875, Avg. loss: 0.623810\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 76.45, NNZs: 2, Bias: 21.000000, T: 7980, Avg. loss: 0.179429\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 76.60, NNZs: 2, Bias: 21.000000, T: 8085, Avg. loss: 0.175619\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 76.75, NNZs: 2, Bias: 21.000000, T: 8190, Avg. loss: 0.171810\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 76.94, NNZs: 2, Bias: 21.000000, T: 8295, Avg. loss: 0.203429\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 77.55, NNZs: 2, Bias: 22.000000, T: 8400, Avg. loss: 0.604000\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 78.23, NNZs: 2, Bias: 22.000000, T: 8505, Avg. loss: 0.192952\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 78.39, NNZs: 2, Bias: 22.000000, T: 8610, Avg. loss: 0.168571\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 78.57, NNZs: 2, Bias: 22.000000, T: 8715, Avg. loss: 0.198762\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 79.18, NNZs: 2, Bias: 23.000000, T: 8820, Avg. loss: 0.589524\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 79.33, NNZs: 2, Bias: 23.000000, T: 8925, Avg. loss: 0.174857\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 79.48, NNZs: 2, Bias: 23.000000, T: 9030, Avg. loss: 0.171048\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 79.64, NNZs: 2, Bias: 23.000000, T: 9135, Avg. loss: 0.167238\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 79.82, NNZs: 2, Bias: 23.000000, T: 9240, Avg. loss: 0.198095\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 80.62, NNZs: 2, Bias: 23.000000, T: 9345, Avg. loss: 0.505429\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 80.02, NNZs: 2, Bias: 24.000000, T: 9450, Avg. loss: 0.360476\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 80.17, NNZs: 2, Bias: 24.000000, T: 9555, Avg. loss: 0.169143\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 80.33, NNZs: 2, Bias: 24.000000, T: 9660, Avg. loss: 0.165333\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 80.52, NNZs: 2, Bias: 24.000000, T: 9765, Avg. loss: 0.194762\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 81.32, NNZs: 2, Bias: 24.000000, T: 9870, Avg. loss: 0.497333\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 80.71, NNZs: 2, Bias: 25.000000, T: 9975, Avg. loss: 0.361429\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 80.86, NNZs: 2, Bias: 25.000000, T: 10080, Avg. loss: 0.167238\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 81.02, NNZs: 2, Bias: 25.000000, T: 10185, Avg. loss: 0.163429\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 81.21, NNZs: 2, Bias: 25.000000, T: 10290, Avg. loss: 0.191429\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 82.01, NNZs: 2, Bias: 25.000000, T: 10395, Avg. loss: 0.489238\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 81.40, NNZs: 2, Bias: 26.000000, T: 10500, Avg. loss: 0.362381\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 81.55, NNZs: 2, Bias: 26.000000, T: 10605, Avg. loss: 0.165333\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 81.71, NNZs: 2, Bias: 26.000000, T: 10710, Avg. loss: 0.161524\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 81.91, NNZs: 2, Bias: 26.000000, T: 10815, Avg. loss: 0.188095\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 82.71, NNZs: 2, Bias: 26.000000, T: 10920, Avg. loss: 0.481143\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 82.09, NNZs: 2, Bias: 27.000000, T: 11025, Avg. loss: 0.363333\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 82.24, NNZs: 2, Bias: 27.000000, T: 11130, Avg. loss: 0.163429\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 82.40, NNZs: 2, Bias: 27.000000, T: 11235, Avg. loss: 0.159619\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 82.60, NNZs: 2, Bias: 27.000000, T: 11340, Avg. loss: 0.184762\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 83.41, NNZs: 2, Bias: 27.000000, T: 11445, Avg. loss: 0.473048\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 82.78, NNZs: 2, Bias: 28.000000, T: 11550, Avg. loss: 0.364286\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 82.93, NNZs: 2, Bias: 28.000000, T: 11655, Avg. loss: 0.161524\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 83.10, NNZs: 2, Bias: 28.000000, T: 11760, Avg. loss: 0.157714\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 83.30, NNZs: 2, Bias: 28.000000, T: 11865, Avg. loss: 0.181429\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 84.11, NNZs: 2, Bias: 28.000000, T: 11970, Avg. loss: 0.464952\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 83.47, NNZs: 2, Bias: 29.000000, T: 12075, Avg. loss: 0.365238\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 83.63, NNZs: 2, Bias: 29.000000, T: 12180, Avg. loss: 0.159619\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 83.79, NNZs: 2, Bias: 29.000000, T: 12285, Avg. loss: 0.155810\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 83.99, NNZs: 2, Bias: 29.000000, T: 12390, Avg. loss: 0.178095\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 84.81, NNZs: 2, Bias: 29.000000, T: 12495, Avg. loss: 0.456857\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 84.16, NNZs: 2, Bias: 30.000000, T: 12600, Avg. loss: 0.366190\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 84.32, NNZs: 2, Bias: 30.000000, T: 12705, Avg. loss: 0.157714\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 84.48, NNZs: 2, Bias: 30.000000, T: 12810, Avg. loss: 0.153905\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 84.69, NNZs: 2, Bias: 30.000000, T: 12915, Avg. loss: 0.174762\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 85.51, NNZs: 2, Bias: 30.000000, T: 13020, Avg. loss: 0.448762\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 84.85, NNZs: 2, Bias: 31.000000, T: 13125, Avg. loss: 0.367143\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 85.01, NNZs: 2, Bias: 31.000000, T: 13230, Avg. loss: 0.155810\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 85.17, NNZs: 2, Bias: 31.000000, T: 13335, Avg. loss: 0.152000\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 85.36, NNZs: 2, Bias: 31.000000, T: 13440, Avg. loss: 0.217905\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 85.91, NNZs: 2, Bias: 32.000000, T: 13545, Avg. loss: 0.517905\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 86.07, NNZs: 2, Bias: 32.000000, T: 13650, Avg. loss: 0.155429\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 86.23, NNZs: 2, Bias: 32.000000, T: 13755, Avg. loss: 0.151619\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 86.43, NNZs: 2, Bias: 32.000000, T: 13860, Avg. loss: 0.172762\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 86.81, NNZs: 2, Bias: 32.000000, T: 13965, Avg. loss: 0.408095\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 86.15, NNZs: 2, Bias: 33.000000, T: 14070, Avg. loss: 0.354000\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 86.31, NNZs: 2, Bias: 33.000000, T: 14175, Avg. loss: 0.153905\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 86.48, NNZs: 2, Bias: 33.000000, T: 14280, Avg. loss: 0.150095\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 86.68, NNZs: 2, Bias: 33.000000, T: 14385, Avg. loss: 0.169429\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 87.06, NNZs: 2, Bias: 33.000000, T: 14490, Avg. loss: 0.402857\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 86.40, NNZs: 2, Bias: 34.000000, T: 14595, Avg. loss: 0.355143\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 86.56, NNZs: 2, Bias: 34.000000, T: 14700, Avg. loss: 0.152381\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 86.73, NNZs: 2, Bias: 34.000000, T: 14805, Avg. loss: 0.148571\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 86.94, NNZs: 2, Bias: 34.000000, T: 14910, Avg. loss: 0.166095\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 87.32, NNZs: 2, Bias: 34.000000, T: 15015, Avg. loss: 0.397619\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 86.65, NNZs: 2, Bias: 35.000000, T: 15120, Avg. loss: 0.356286\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 86.81, NNZs: 2, Bias: 35.000000, T: 15225, Avg. loss: 0.150857\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 86.98, NNZs: 2, Bias: 35.000000, T: 15330, Avg. loss: 0.147048\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 87.18, NNZs: 2, Bias: 35.000000, T: 15435, Avg. loss: 0.208000\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 87.31, NNZs: 2, Bias: 36.000000, T: 15540, Avg. loss: 0.418381\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 88.15, NNZs: 2, Bias: 36.000000, T: 15645, Avg. loss: 0.369714\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 88.31, NNZs: 2, Bias: 36.000000, T: 15750, Avg. loss: 0.148000\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 88.48, NNZs: 2, Bias: 36.000000, T: 15855, Avg. loss: 0.144190\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 88.67, NNZs: 2, Bias: 36.000000, T: 15960, Avg. loss: 0.204000\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 88.81, NNZs: 2, Bias: 37.000000, T: 16065, Avg. loss: 0.410571\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 89.64, NNZs: 2, Bias: 37.000000, T: 16170, Avg. loss: 0.356286\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 89.81, NNZs: 2, Bias: 37.000000, T: 16275, Avg. loss: 0.145143\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 89.97, NNZs: 2, Bias: 37.000000, T: 16380, Avg. loss: 0.141333\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 90.17, NNZs: 2, Bias: 37.000000, T: 16485, Avg. loss: 0.200000\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 90.30, NNZs: 2, Bias: 38.000000, T: 16590, Avg. loss: 0.402762\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 91.14, NNZs: 2, Bias: 38.000000, T: 16695, Avg. loss: 0.342857\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 91.30, NNZs: 2, Bias: 38.000000, T: 16800, Avg. loss: 0.142286\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 91.51, NNZs: 2, Bias: 38.000000, T: 16905, Avg. loss: 0.160095\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 91.45, NNZs: 2, Bias: 38.000000, T: 17010, Avg. loss: 0.362952\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 91.97, NNZs: 2, Bias: 39.000000, T: 17115, Avg. loss: 0.465048\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 92.14, NNZs: 2, Bias: 39.000000, T: 17220, Avg. loss: 0.140000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 92.34, NNZs: 2, Bias: 39.000000, T: 17325, Avg. loss: 0.156095\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 92.29, NNZs: 2, Bias: 39.000000, T: 17430, Avg. loss: 0.361810\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 92.80, NNZs: 2, Bias: 40.000000, T: 17535, Avg. loss: 0.456095\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 92.97, NNZs: 2, Bias: 40.000000, T: 17640, Avg. loss: 0.137714\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 93.18, NNZs: 2, Bias: 40.000000, T: 17745, Avg. loss: 0.152095\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 93.13, NNZs: 2, Bias: 40.000000, T: 17850, Avg. loss: 0.360667\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 93.11, NNZs: 2, Bias: 41.000000, T: 17955, Avg. loss: 0.530190\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 93.27, NNZs: 2, Bias: 41.000000, T: 18060, Avg. loss: 0.141905\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 93.44, NNZs: 2, Bias: 41.000000, T: 18165, Avg. loss: 0.138095\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 93.61, NNZs: 2, Bias: 41.000000, T: 18270, Avg. loss: 0.134286\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 93.81, NNZs: 2, Bias: 41.000000, T: 18375, Avg. loss: 0.189905\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 93.49, NNZs: 2, Bias: 42.000000, T: 18480, Avg. loss: 0.371048\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 94.33, NNZs: 2, Bias: 42.000000, T: 18585, Avg. loss: 0.312857\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 94.49, NNZs: 2, Bias: 42.000000, T: 18690, Avg. loss: 0.135619\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 94.70, NNZs: 2, Bias: 42.000000, T: 18795, Avg. loss: 0.150095\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 94.65, NNZs: 2, Bias: 42.000000, T: 18900, Avg. loss: 0.362476\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 94.31, NNZs: 2, Bias: 43.000000, T: 19005, Avg. loss: 0.371238\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 95.16, NNZs: 2, Bias: 43.000000, T: 19110, Avg. loss: 0.303714\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 95.33, NNZs: 2, Bias: 43.000000, T: 19215, Avg. loss: 0.133333\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 95.54, NNZs: 2, Bias: 43.000000, T: 19320, Avg. loss: 0.146095\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 95.49, NNZs: 2, Bias: 43.000000, T: 19425, Avg. loss: 0.361333\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 95.14, NNZs: 2, Bias: 44.000000, T: 19530, Avg. loss: 0.371429\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 95.99, NNZs: 2, Bias: 44.000000, T: 19635, Avg. loss: 0.294571\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 96.16, NNZs: 2, Bias: 44.000000, T: 19740, Avg. loss: 0.131048\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 96.37, NNZs: 2, Bias: 44.000000, T: 19845, Avg. loss: 0.142095\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 96.32, NNZs: 2, Bias: 44.000000, T: 19950, Avg. loss: 0.360190\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 95.97, NNZs: 2, Bias: 45.000000, T: 20055, Avg. loss: 0.371619\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 96.82, NNZs: 2, Bias: 45.000000, T: 20160, Avg. loss: 0.285429\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 96.99, NNZs: 2, Bias: 45.000000, T: 20265, Avg. loss: 0.128762\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 97.20, NNZs: 2, Bias: 45.000000, T: 20370, Avg. loss: 0.184000\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 97.15, NNZs: 2, Bias: 45.000000, T: 20475, Avg. loss: 0.353619\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 97.18, NNZs: 2, Bias: 46.000000, T: 20580, Avg. loss: 0.444190\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 97.35, NNZs: 2, Bias: 46.000000, T: 20685, Avg. loss: 0.130286\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 97.52, NNZs: 2, Bias: 46.000000, T: 20790, Avg. loss: 0.126476\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 97.73, NNZs: 2, Bias: 46.000000, T: 20895, Avg. loss: 0.178286\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 97.69, NNZs: 2, Bias: 46.000000, T: 21000, Avg. loss: 0.351333\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 97.71, NNZs: 2, Bias: 47.000000, T: 21105, Avg. loss: 0.444000\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 97.88, NNZs: 2, Bias: 47.000000, T: 21210, Avg. loss: 0.128000\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 98.09, NNZs: 2, Bias: 47.000000, T: 21315, Avg. loss: 0.138095\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 98.04, NNZs: 2, Bias: 47.000000, T: 21420, Avg. loss: 0.360952\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 97.69, NNZs: 2, Bias: 48.000000, T: 21525, Avg. loss: 0.350476\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 98.54, NNZs: 2, Bias: 48.000000, T: 21630, Avg. loss: 0.270571\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 98.71, NNZs: 2, Bias: 48.000000, T: 21735, Avg. loss: 0.125714\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 98.93, NNZs: 2, Bias: 48.000000, T: 21840, Avg. loss: 0.134095\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 98.88, NNZs: 2, Bias: 48.000000, T: 21945, Avg. loss: 0.359810\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 98.52, NNZs: 2, Bias: 49.000000, T: 22050, Avg. loss: 0.350667\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 99.38, NNZs: 2, Bias: 49.000000, T: 22155, Avg. loss: 0.261429\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 99.55, NNZs: 2, Bias: 49.000000, T: 22260, Avg. loss: 0.123429\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 99.75, NNZs: 2, Bias: 49.000000, T: 22365, Avg. loss: 0.175619\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 99.71, NNZs: 2, Bias: 49.000000, T: 22470, Avg. loss: 0.353238\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 99.65, NNZs: 2, Bias: 50.000000, T: 22575, Avg. loss: 0.488286\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 99.82, NNZs: 2, Bias: 50.000000, T: 22680, Avg. loss: 0.124762\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 99.99, NNZs: 2, Bias: 50.000000, T: 22785, Avg. loss: 0.120952\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 100.21, NNZs: 2, Bias: 50.000000, T: 22890, Avg. loss: 0.168952\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 100.17, NNZs: 2, Bias: 50.000000, T: 22995, Avg. loss: 0.350286\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 100.10, NNZs: 2, Bias: 51.000000, T: 23100, Avg. loss: 0.490571\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 100.27, NNZs: 2, Bias: 51.000000, T: 23205, Avg. loss: 0.122286\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 100.44, NNZs: 2, Bias: 51.000000, T: 23310, Avg. loss: 0.118476\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 100.66, NNZs: 2, Bias: 51.000000, T: 23415, Avg. loss: 0.162286\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 100.62, NNZs: 2, Bias: 51.000000, T: 23520, Avg. loss: 0.347333\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 100.54, NNZs: 2, Bias: 52.000000, T: 23625, Avg. loss: 0.492857\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 100.71, NNZs: 2, Bias: 52.000000, T: 23730, Avg. loss: 0.119810\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 100.94, NNZs: 2, Bias: 52.000000, T: 23835, Avg. loss: 0.123429\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 100.89, NNZs: 2, Bias: 52.000000, T: 23940, Avg. loss: 0.356286\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 100.86, NNZs: 2, Bias: 52.000000, T: 24045, Avg. loss: 0.343905\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 100.85, NNZs: 2, Bias: 53.000000, T: 24150, Avg. loss: 0.419810\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 101.02, NNZs: 2, Bias: 53.000000, T: 24255, Avg. loss: 0.117714\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 101.24, NNZs: 2, Bias: 53.000000, T: 24360, Avg. loss: 0.161905\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 101.20, NNZs: 2, Bias: 53.000000, T: 24465, Avg. loss: 0.348095\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 101.12, NNZs: 2, Bias: 54.000000, T: 24570, Avg. loss: 0.472571\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 101.30, NNZs: 2, Bias: 54.000000, T: 24675, Avg. loss: 0.119048\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 101.47, NNZs: 2, Bias: 54.000000, T: 24780, Avg. loss: 0.115238\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 101.70, NNZs: 2, Bias: 54.000000, T: 24885, Avg. loss: 0.155238\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 101.66, NNZs: 2, Bias: 54.000000, T: 24990, Avg. loss: 0.345143\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 101.57, NNZs: 2, Bias: 55.000000, T: 25095, Avg. loss: 0.474857\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 101.74, NNZs: 2, Bias: 55.000000, T: 25200, Avg. loss: 0.116571\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 101.97, NNZs: 2, Bias: 55.000000, T: 25305, Avg. loss: 0.117429\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 101.93, NNZs: 2, Bias: 55.000000, T: 25410, Avg. loss: 0.354095\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 101.90, NNZs: 2, Bias: 55.000000, T: 25515, Avg. loss: 0.341714\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 101.80, NNZs: 2, Bias: 56.000000, T: 25620, Avg. loss: 0.478286\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 101.97, NNZs: 2, Bias: 56.000000, T: 25725, Avg. loss: 0.114286\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 102.20, NNZs: 2, Bias: 56.000000, T: 25830, Avg. loss: 0.153905\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 102.16, NNZs: 2, Bias: 56.000000, T: 25935, Avg. loss: 0.345238\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 102.07, NNZs: 2, Bias: 57.000000, T: 26040, Avg. loss: 0.456762\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 102.24, NNZs: 2, Bias: 57.000000, T: 26145, Avg. loss: 0.115619\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 102.42, NNZs: 2, Bias: 57.000000, T: 26250, Avg. loss: 0.111810\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 251\n",
      "Norm: 102.65, NNZs: 2, Bias: 57.000000, T: 26355, Avg. loss: 0.147238\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 252\n",
      "Norm: 102.62, NNZs: 2, Bias: 57.000000, T: 26460, Avg. loss: 0.342286\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 253\n",
      "Norm: 102.52, NNZs: 2, Bias: 58.000000, T: 26565, Avg. loss: 0.459048\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 254\n",
      "Norm: 102.69, NNZs: 2, Bias: 58.000000, T: 26670, Avg. loss: 0.113143\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 255\n",
      "Norm: 102.87, NNZs: 2, Bias: 58.000000, T: 26775, Avg. loss: 0.109333\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 256\n",
      "Norm: 103.11, NNZs: 2, Bias: 58.000000, T: 26880, Avg. loss: 0.140571\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 257\n",
      "Norm: 103.08, NNZs: 2, Bias: 58.000000, T: 26985, Avg. loss: 0.339333\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 258\n",
      "Norm: 102.96, NNZs: 2, Bias: 59.000000, T: 27090, Avg. loss: 0.461333\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 259\n",
      "Norm: 103.14, NNZs: 2, Bias: 59.000000, T: 27195, Avg. loss: 0.110667\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 260\n",
      "Norm: 103.37, NNZs: 2, Bias: 59.000000, T: 27300, Avg. loss: 0.146095\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 261\n",
      "Norm: 103.34, NNZs: 2, Bias: 59.000000, T: 27405, Avg. loss: 0.342857\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 262\n",
      "Norm: 102.90, NNZs: 2, Bias: 60.000000, T: 27510, Avg. loss: 0.341333\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 263\n",
      "Norm: 103.78, NNZs: 2, Bias: 60.000000, T: 27615, Avg. loss: 0.199143\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 264\n",
      "Norm: 104.01, NNZs: 2, Bias: 60.000000, T: 27720, Avg. loss: 0.144000\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 265\n",
      "Norm: 103.98, NNZs: 2, Bias: 60.000000, T: 27825, Avg. loss: 0.342762\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 266\n",
      "Norm: 103.54, NNZs: 2, Bias: 61.000000, T: 27930, Avg. loss: 0.336095\n",
      "Total training time: 0.98 seconds.\n",
      "Convergence after 266 epochs took 0.98 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.42, NNZs: 2, Bias: 1.000000, T: 105, Avg. loss: 10.328952\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.40, NNZs: 2, Bias: 2.000000, T: 210, Avg. loss: 9.948476\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 16.67, NNZs: 2, Bias: 4.000000, T: 315, Avg. loss: 8.952000\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.58, NNZs: 2, Bias: 5.000000, T: 420, Avg. loss: 8.811810\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.29, NNZs: 2, Bias: 7.000000, T: 525, Avg. loss: 7.532952\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 23.76, NNZs: 2, Bias: 8.000000, T: 630, Avg. loss: 8.932286\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 22.49, NNZs: 2, Bias: 10.000000, T: 735, Avg. loss: 7.510667\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 25.58, NNZs: 2, Bias: 11.000000, T: 840, Avg. loss: 9.617619\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 23.60, NNZs: 2, Bias: 13.000000, T: 945, Avg. loss: 7.656286\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 26.97, NNZs: 2, Bias: 14.000000, T: 1050, Avg. loss: 9.106095\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 25.90, NNZs: 2, Bias: 16.000000, T: 1155, Avg. loss: 8.306190\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 24.55, NNZs: 2, Bias: 18.000000, T: 1260, Avg. loss: 7.402857\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 26.51, NNZs: 2, Bias: 19.000000, T: 1365, Avg. loss: 9.437143\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 24.78, NNZs: 2, Bias: 21.000000, T: 1470, Avg. loss: 8.382000\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 23.18, NNZs: 2, Bias: 23.000000, T: 1575, Avg. loss: 7.767619\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 25.87, NNZs: 2, Bias: 24.000000, T: 1680, Avg. loss: 8.813524\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 28.11, NNZs: 2, Bias: 25.000000, T: 1785, Avg. loss: 9.049905\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.77, NNZs: 2, Bias: 26.000000, T: 1890, Avg. loss: 8.375905\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 30.55, NNZs: 2, Bias: 27.000000, T: 1995, Avg. loss: 7.706762\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.82, NNZs: 2, Bias: 29.000000, T: 2100, Avg. loss: 8.298000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 27.22, NNZs: 2, Bias: 31.000000, T: 2205, Avg. loss: 7.676000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 29.90, NNZs: 2, Bias: 32.000000, T: 2310, Avg. loss: 8.635238\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 28.28, NNZs: 2, Bias: 34.000000, T: 2415, Avg. loss: 7.642381\n",
      "Total training time: 0.10 seconds.\n",
      "Convergence after 23 epochs took 0.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.77, NNZs: 2, Bias: -2.000000, T: 105, Avg. loss: 8.112095\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.88, NNZs: 2, Bias: -4.000000, T: 210, Avg. loss: 6.382381\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.96, NNZs: 2, Bias: -7.000000, T: 315, Avg. loss: 7.365429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.53, NNZs: 2, Bias: -9.000000, T: 420, Avg. loss: 7.002286\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.11, NNZs: 2, Bias: -11.000000, T: 525, Avg. loss: 6.900762\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 31.07, NNZs: 2, Bias: -12.000000, T: 630, Avg. loss: 6.550381\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 33.78, NNZs: 2, Bias: -14.000000, T: 735, Avg. loss: 6.780571\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.17, NNZs: 2, Bias: -16.000000, T: 840, Avg. loss: 6.789238\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 38.59, NNZs: 2, Bias: -18.000000, T: 945, Avg. loss: 6.742286\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 41.16, NNZs: 2, Bias: -19.000000, T: 1050, Avg. loss: 6.424381\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 42.79, NNZs: 2, Bias: -21.000000, T: 1155, Avg. loss: 6.734952\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 42.04, NNZs: 2, Bias: -23.000000, T: 1260, Avg. loss: 7.010381\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 43.61, NNZs: 2, Bias: -24.000000, T: 1365, Avg. loss: 6.217905\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 42.80, NNZs: 2, Bias: -26.000000, T: 1470, Avg. loss: 6.981429\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 43.80, NNZs: 2, Bias: -27.000000, T: 1575, Avg. loss: 6.430667\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 43.44, NNZs: 2, Bias: -28.000000, T: 1680, Avg. loss: 6.827714\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 42.57, NNZs: 2, Bias: -30.000000, T: 1785, Avg. loss: 6.927524\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 43.64, NNZs: 2, Bias: -31.000000, T: 1890, Avg. loss: 6.366286\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 42.17, NNZs: 2, Bias: -33.000000, T: 1995, Avg. loss: 6.667714\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 43.91, NNZs: 2, Bias: -34.000000, T: 2100, Avg. loss: 6.046952\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 42.41, NNZs: 2, Bias: -36.000000, T: 2205, Avg. loss: 6.630000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 43.56, NNZs: 2, Bias: -37.000000, T: 2310, Avg. loss: 6.273524\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 43.20, NNZs: 2, Bias: -38.000000, T: 2415, Avg. loss: 6.730667\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 42.85, NNZs: 2, Bias: -39.000000, T: 2520, Avg. loss: 6.719905\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 42.04, NNZs: 2, Bias: -41.000000, T: 2625, Avg. loss: 6.456476\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 42.43, NNZs: 2, Bias: -41.000000, T: 2730, Avg. loss: 6.345524\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 41.58, NNZs: 2, Bias: -43.000000, T: 2835, Avg. loss: 6.429714\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 41.47, NNZs: 2, Bias: -44.000000, T: 2940, Avg. loss: 6.318000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 41.95, NNZs: 2, Bias: -44.000000, T: 3045, Avg. loss: 6.311048\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 41.01, NNZs: 2, Bias: -46.000000, T: 3150, Avg. loss: 6.403333\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 40.90, NNZs: 2, Bias: -47.000000, T: 3255, Avg. loss: 6.286952\n",
      "Total training time: 0.14 seconds.\n",
      "Convergence after 31 epochs took 0.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(alpha=1e-05, max_iter=1200, n_iter_no_change=11, n_jobs=1,\n",
       "           shuffle=False, tol=1e-05, verbose=6)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(alpha=1e-05, max_iter=1200, n_iter_no_change=11, n_jobs=1,\n",
       "           shuffle=False, tol=1e-05, verbose=6)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron(alpha=1e-05, max_iter=1200, n_iter_no_change=11, n_jobs=1,\n",
       "           shuffle=False, tol=1e-05, verbose=6)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dcc0f0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7555555555555555"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=clf.predict(x_test)\n",
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45412719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c5737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e143ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db8ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5f9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cd63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
